{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d324267c",
   "metadata": {},
   "source": [
    "# All the information is on the task(master fan wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810e40e",
   "metadata": {},
   "source": [
    "In this notebook we try to use Python's BeautifulSoup module to scrape the wording of all the tasks from series 14 of the popular TV show Taskmaster from the fan wiki:\n",
    "\n",
    "https://taskmaster.fandom.com/wiki/Series_13\n",
    "\n",
    "with a view to analysing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4d10e",
   "metadata": {},
   "source": [
    "## The main tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b897894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ususal uploads\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://taskmaster.fandom.com/wiki/Series_13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1471bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starts = list(soup.find_all(\"tr\", class_='tmtablerow'))\n",
    "len(all_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a495838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting them all in a single list\n",
    "\n",
    "all_tasks = []\n",
    "for i in range(len(all_starts)):\n",
    "    if len(list(all_starts[i])) > 2:\n",
    "        all_tasks.append(str(list(all_starts[i])[3]))\n",
    "    else:\n",
    "        all_tasks.append(str(list(all_starts[i])[1]))\n",
    "    \n",
    "            \n",
    "pprint(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8feb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the <td>s from the beinnings \n",
    "\n",
    "all_tasks = [task[4:] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stuff from the beginnings\n",
    "\n",
    "for i in range(len(all_tasks)):\n",
    "    if 'Prize:' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][14:]\n",
    "    if 'Team Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][18:]\n",
    "    if 'Team' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "    if 'Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "        \n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3484691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stuff from the end\n",
    "\n",
    "all_tasks = [task[:-7] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[14] = \"Enable Alex to bite his duck. You may not encroach upon the decking. Fastest wins. for the person who gets Alex the least wet.\"\n",
    "all_tasks[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[33] = \"Sing Ive won in a low voice and this tiebreak in a high voice. Greatest vocal range wins\"\n",
    "all_tasks[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[38] = \"Completely consume your beautiful sculpture. Fastest wins.\"\n",
    "all_tasks[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[43] = \"Walk through this doorway wearing the longest shoes and the biggest hat. You must open the door and walk through this doorway wearing your long shoes and big hat within the next 20 minutes. Most stylish.\"\n",
    "all_tasks[43]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3368435",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e22d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_split = [task.split() for task in all_tasks]\n",
    "pprint(tasks_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ccfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_words = []\n",
    "for task in tasks_split:\n",
    "    task_words += task\n",
    "\n",
    "task_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ab7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_lower = [task.lower() for task in task_words]\n",
    "tasks_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_punc = []\n",
    "\n",
    "for word in tasks_lower:\n",
    "    for punctuation in string.punctuation:\n",
    "        word = word.replace(punctuation, '')\n",
    "    tasks_no_punc.append(word)\n",
    "        \n",
    "tasks_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a710819",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_stop = [word for word in tasks_no_punc if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Lemmatizing the verbs\n",
    "task_verb_lem = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in tasks_no_stop\n",
    "]\n",
    "\n",
    "task_verb_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_final = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in task_verb_lem\n",
    "]\n",
    "\n",
    "tasks_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff4a309",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f20ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tasks_final)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77340a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ff772",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb344df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for words in tasks_final:\n",
    "    text += words + ' '\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d825c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud)#, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc9ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
