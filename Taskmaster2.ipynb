{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb06819",
   "metadata": {},
   "source": [
    "# All the information is on the task(master fan wiki)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66274976",
   "metadata": {},
   "source": [
    "In this notebook we try to use Python's BeautifulSoup module to scrape the wording of all the tasks from series 14 of the popular TV show Taskmaster from the fan wiki:\n",
    "\n",
    "https://taskmaster.fandom.com/wiki/Series_2\n",
    "\n",
    "with a view to analysing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e4d67d",
   "metadata": {},
   "source": [
    "## The main tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ususal uploads\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://taskmaster.fandom.com/wiki/Series_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starts = list(soup.find_all(\"tr\", class_='tmtablerow'))\n",
    "len(all_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd66d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting them all in a single list\n",
    "\n",
    "all_tasks = []\n",
    "for i in range(len(all_starts)):\n",
    "    if len(list(all_starts[i])) > 2:\n",
    "        all_tasks.append(str(list(all_starts[i])[3]))\n",
    "    else:\n",
    "        all_tasks.append(str(list(all_starts[i])[1]))\n",
    "    \n",
    "            \n",
    "pprint(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the <td>s from the beinnings \n",
    "\n",
    "all_tasks = [task[4:] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stuff from the beginnings\n",
    "\n",
    "for i in range(len(all_tasks)):\n",
    "    if 'Prize:' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][14:]\n",
    "    if 'Team Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][18:]\n",
    "    if 'Team' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "    if 'Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "        \n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stuff from the end\n",
    "\n",
    "all_tasks = [task[:-7] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for problems\n",
    "\n",
    "all_tasks[3] = 'Find out the following information from this Swedish person. The Swedish person may not speak or write in English'\n",
    "all_tasks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[9] = 'Order the following pizza for the Taskmaster: Extra large vegetarian pizza with pepperoni and bacon, and without tomato and cheese. You may not use the following words: EXTRA, LARGE, VEGETARIAN, PIZZA, PEPPERONI, BACON, TOMATO, CHEESE. Make the pizza person say the word bubbles'\n",
    "all_tasks[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[16] = 'Put the earplugs in your ears and the ear protectors over the earplugs, then continue reading. You must remain within your bandstand. Instruct the next person to open their task.'\n",
    "all_tasks[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ffffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[17] = 'Do not read this out loud. Get a potato.'\n",
    "all_tasks[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks[23] = 'Guess who set you each task.'\n",
    "all_tasks[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eeeba8",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59acb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_split = [task.split() for task in all_tasks]\n",
    "pprint(tasks_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_words = []\n",
    "for task in tasks_split:\n",
    "    task_words += task\n",
    "\n",
    "task_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63778f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_lower = [task.lower() for task in task_words]\n",
    "tasks_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_punc = []\n",
    "\n",
    "for word in tasks_lower:\n",
    "    for punctuation in string.punctuation:\n",
    "        word = word.replace(punctuation, '')\n",
    "    tasks_no_punc.append(word)\n",
    "        \n",
    "tasks_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95002a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_stop = [word for word in tasks_no_punc if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3616ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Lemmatizing the verbs\n",
    "task_verb_lem = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in tasks_no_stop\n",
    "]\n",
    "\n",
    "task_verb_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_final = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in task_verb_lem\n",
    "]\n",
    "\n",
    "tasks_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f07327",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tasks_final)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57717fea",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for words in tasks_final:\n",
    "    text += words + ' '\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f80b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
