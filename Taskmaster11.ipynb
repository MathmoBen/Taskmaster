{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628744ca",
   "metadata": {},
   "source": [
    "# All the information is on the task(master fan wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9333bec",
   "metadata": {},
   "source": [
    "In this notebook we try to use Python's BeautifulSoup module to scrape the wording of all the tasks from series 14 of the popular TV show Taskmaster from the fan wiki:\n",
    "\n",
    "https://taskmaster.fandom.com/wiki/Series_11\n",
    "\n",
    "with a view to analysing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9c3ab",
   "metadata": {},
   "source": [
    "## The main tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff06fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ususal uploads\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae935c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://taskmaster.fandom.com/wiki/Series_11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fde523",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c054c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starts = list(soup.find_all(\"tr\", class_='tmtablerow'))\n",
    "len(all_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting them all in a single list\n",
    "\n",
    "all_tasks = []\n",
    "for i in range(len(all_starts)):\n",
    "    if len(list(all_starts[i])) > 2:\n",
    "        all_tasks.append(str(list(all_starts[i])[3]))\n",
    "    else:\n",
    "        all_tasks.append(str(list(all_starts[i])[1]))\n",
    "    \n",
    "            \n",
    "pprint(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the <td>s from the beinnings \n",
    "\n",
    "all_tasks = [task[4:] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stuff from the beginnings\n",
    "\n",
    "for i in range(len(all_tasks)):\n",
    "    if 'Prize:' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][14:]\n",
    "    if 'Team Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][18:]\n",
    "    if 'Team' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "    if 'Live' in all_tasks[i]:\n",
    "        all_tasks[i] = all_tasks[i][13:]\n",
    "        \n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf64542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stuff from the end\n",
    "\n",
    "all_tasks = [task[:-7] for task in all_tasks]\n",
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d21d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b045fe",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_split = [task.split() for task in all_tasks]\n",
    "pprint(tasks_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_words = []\n",
    "for task in tasks_split:\n",
    "    task_words += task\n",
    "\n",
    "task_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477463a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_lower = [task.lower() for task in task_words]\n",
    "tasks_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3922913",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_punc = []\n",
    "\n",
    "for word in tasks_lower:\n",
    "    for punctuation in string.punctuation:\n",
    "        word = word.replace(punctuation, '')\n",
    "    tasks_no_punc.append(word)\n",
    "        \n",
    "tasks_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20868c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_no_stop = [word for word in tasks_no_punc if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tasks_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Lemmatizing the verbs\n",
    "task_verb_lem = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in tasks_no_stop\n",
    "]\n",
    "\n",
    "task_verb_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_final = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in task_verb_lem\n",
    "]\n",
    "\n",
    "tasks_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c37a87",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5abff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tasks_final)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464566cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].value_counts().nlargest(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15a3f6",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f526d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for words in tasks_final:\n",
    "    text += words + ' '\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud)#, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b371a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
